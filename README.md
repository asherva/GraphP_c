timport requests
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# ===== ×”×’×“×¨×•×ª =====
SERVER = "https://your-tableau-server"
USERNAME = "your-username"
PASSWORD = "your-password"
API_VERSION = "3.22"
MAX_WORKERS = 10
VERIFY_SSL = False  # ×¢×§×™×¤×ª ×‘×“×™×§×ª SSL

# ×‘×™×˜×•×œ ××–×”×¨×•×ª SSL
requests.packages.urllib3.disable_warnings()

# ===== ×¤×•× ×§×¦×™×•×ª ×‘×“×™×§×” =====
def test_rest_api():
    """×‘×•×“×§ ×—×™×‘×•×¨ ×œ-REST API ×•××—×–×™×¨ token ×•-site_id"""
    print("ğŸ” ×‘×•×“×§ ×—×™×‘×•×¨ ×œ-REST API...")
    url = f"{SERVER}/api/{API_VERSION}/auth/signin"
    payload = {
        "credentials": {
            "name": USERNAME,
            "password": PASSWORD,
            "site": {"contentUrl": ""}
        }
    }
    r = requests.post(url, json=payload, verify=VERIFY_SSL)
    r.raise_for_status()
    res = r.json()["credentials"]
    print("âœ… REST API ××—×•×‘×¨")
    return res["token"], res["site"]["id"], res["user"]["id"]

def test_metadata_api(token, site_id):
    """×‘×•×“×§ ×—×™×‘×•×¨ ×œ-Metadata API"""
    print("ğŸ” ×‘×•×“×§ ×—×™×‘×•×¨ ×œ-Metadata API...")
    query = "{ workbooks { name } }"
    url = f"{SERVER}/api/metadata/graphql"
    headers = {
        "X-Tableau-Auth": token,
        "X-Tableau-Site-Id": site_id,
        "Content-Type": "application/json"
    }
    r = requests.post(url, json={"query": query}, headers=headers, verify=VERIFY_SSL)
    r.raise_for_status()
    data = r.json()
    if "errors" in data:
        raise RuntimeError(f"Metadata API ××—×–×™×¨ ×©×’×™××”: {data['errors']}")
    print(f"âœ… Metadata API ×¤×¢×™×œ â€“ × ××¦××• {len(data['data']['workbooks'])} ×“×•×—×•×ª (××• ×¤×—×•×ª ×œ×¤×™ ×”×¨×©××•×ª×™×š)")

# ===== ×¤×•× ×§×¦×™×•×ª ×¢×™×§×¨×™×•×ª =====
def get_sites(token):
    url = f"{SERVER}/api/{API_VERSION}/sites?pageSize=1000"
    headers = {"X-Tableau-Auth": token}
    r = requests.get(url, headers=headers, verify=VERIFY_SSL)
    r.raise_for_status()
    return r.json()["sites"]["site"]

def graphql_query(token, site_id, query):
    url = f"{SERVER}/api/metadata/graphql"
    headers = {
        "X-Tableau-Auth": token,
        "X-Tableau-Site-Id": site_id,
        "Content-Type": "application/json"
    }
    r = requests.post(url, json={"query": query}, headers=headers, verify=VERIFY_SSL)
    r.raise_for_status()
    return r.json()

def process_site(site, token):
    site_id = site["id"]
    site_name = site["name"]
    print(f"ğŸ” ×¡×•×¨×§ ××ª ×”××ª×¨: {site_name}")

    query = """
    {
      workbooks {
        name
        datasources {
          name
          upstreamTables {
            name
            schema
            connectionType
          }
          ... on CustomSQLTable {
            query
          }
        }
      }
    }
    """

    rows = []
    try:
        data = graphql_query(token, site_id, query)
        if "data" in data and "workbooks" in data["data"]:
            for wb in data["data"]["workbooks"]:
                wb_name = wb["name"]
                for ds in wb.get("datasources", []):
                    ds_name = ds["name"]
                    sql_text = ds.get("query", None)
                    if ds.get("upstreamTables"):
                        for tbl in ds["upstreamTables"]:
                            rows.append({
                                "Site": site_name,
                                "Workbook": wb_name,
                                "DataSource": ds_name,
                                "Table": tbl["name"],
                                "Schema": tbl.get("schema", ""),
                                "ConnectionType": tbl.get("connectionType", ""),
                                "SQL": sql_text
                            })
                    else:
                        rows.append({
                            "Site": site_name,
                            "Workbook": wb_name,
                            "DataSource": ds_name,
                            "Table": "",
                            "Schema": "",
                            "ConnectionType": "",
                            "SQL": sql_text
                        })
    except Exception as e:
        print(f"âš ï¸ ×©×’×™××” ×‘×¡×¨×™×§×ª ×”××ª×¨ {site_name}: {e}")
        rows.append({
            "Site": site_name,
            "Workbook": "ERROR",
            "DataSource": "",
            "Table": "",
            "Schema": "",
            "ConnectionType": "",
            "SQL": f"×©×’×™××”: {e}"
        })
    return rows

# ===== ×”×¨×¦×” ×¨××©×™×ª =====
if __name__ == "__main__":
    try:
        # ×‘×“×™×§×•×ª ×œ×¤× ×™ ×¨×™×¦×”
        token, default_site_id, user_id = test_rest_api()
        test_metadata_api(token, default_site_id)

        # ×¡×¨×™×§×” ××œ××”
        sites = get_sites(token)
        all_rows = []
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_site = {executor.submit(process_site, site, token): site for site in sites}
            for future in as_completed(future_to_site):
                all_rows.extend(future.result())

        # ×©××™×¨×” ×œ×¤×œ×˜
        df = pd.DataFrame(all_rows)
        df.to_excel("tableau_all_sites_sql_metadata.xlsx", index=False)
        print("âœ… ×”×§×•×‘×¥ 'tableau_all_sites_sql_metadata.xlsx' × ×•×¦×¨ ×‘×”×¦×œ×—×”.")

    except Exception as e:
        print(f"âŒ ×”×‘×“×™×§×” × ×›×©×œ×”: {e}")
