# app_internal.py
import streamlit as st
import pyodbc
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
from langchain.docstore.document import Document
from langchain_community.vectorstores import FAISS
import numpy as np
from gpt4all import GPT4All  # ××• ×”×—×œ×£ ×œ-Ollama ×× ×ª×¨×¦×”

# --- ×˜×¢×™× ×ª × ×ª×•× ×™× ×-MSSQL ---
def load_sales_table():
    conn_str = (
        "DRIVER={ODBC Driver 18 for SQL Server};"
        "SERVER=YOUR_SERVER\\INSTANCE;"
        "DATABASE=SalesDB;"
        "Trusted_Connection=yes;"
        "TrustServerCertificate=yes;"
    )
    conn = pyodbc.connect(conn_str)
    query = "SELECT TOP 10000 * FROM SalesTable"  # ×”×—×œ×£ ×œ×©× ×”×˜×‘×œ×” ×©×œ×š
    df = pd.read_sql(query, conn)
    conn.close()
    return df

# --- ×™×¦×™×¨×ª Vector Store ---
def df_to_docs(df):
    docs = []
    for _, row in df.iterrows():
        text = " | ".join([f"{col}: {row[col]}" for col in df.columns])
        docs.append(Document(page_content=text))
    return docs

def build_faiss_index(docs, model):
    texts = [d.page_content for d in docs]
    embeddings = model.encode(texts, show_progress_bar=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(embeddings).astype("float32"))
    return index

# --- ×©××™×œ×ª LLM ××§×•××™ (GPT4All) ---
def query_gpt4all(llm, question, context):
    prompt = f"""×‘×”×ª×‘×¡×¡ ×¢×œ ×”××™×“×¢ ×”×‘×:
{context}

×¢× ×” ×¢×œ ×”×©××œ×”:
{question}
"""
    response = llm.prompt(prompt)
    return response

# --- ×”×××©×§ ---
st.title("ğŸ’¼ ×¦'××˜ ×¢×¡×§×™ ×¤× ×™××™ - MSSQL + LLM ××§×•××™")

@st.cache_data(ttl=3600)
def prepare_data():
    df = load_sales_table()
    model = SentenceTransformer("all-MiniLM-L6-v2")
    docs = df_to_docs(df)
    index = build_faiss_index(docs, model)
    return df, docs, model, index

df, docs, model, index = prepare_data()
st.write(f"×˜×¢×•× ×™× {len(df)} ×©×•×¨×•×ª × ×ª×•× ×™×.")

llm = GPT4All("mistral-7b-instruct.Q4_0.bin")  # ×•×“× ×©×”××•×“×œ ×§×™×™× ×‘××—×©×‘ ×©×œ×š

question = st.text_input("×›×ª×•×‘ ×©××œ×” ×¢×¡×§×™×ª:")

if question:
    q_emb = model.encode([question]).astype("float32")
    D, I = index.search(q_emb, 3)  # ×§×— 3 ×ª×•×¦××•×ª ×¨×œ×•×•× ×˜×™×•×ª
    context = "\n\n".join([docs[i].page_content for i in I[0]])
    with st.spinner("××—×©×‘ ×ª×©×•×‘×”..."):
        answer = query_gpt4all(llm, question, context)
    st.markdown("### ×ª×©×•×‘×”:")
    st.write(answer)            return self.emb.embed_documents(texts)
        else:
            arr = self.st.encode(texts, show_progress_bar=False)
            return [list(x) for x in arr]

def build_vectorstore_from_df(df: pd.DataFrame, cfg_path="config.json", text_cols=None, recreate=False):
    cfg = load_config(cfg_path)
    vs_cfg = cfg.get("vectorstore", {})
    index_path = vs_cfg.get("index_path", "faiss_index")

    # ×‘×—×¨ ×¢××•×“×•×ª ×× ×œ× ×¡×•×¤×§×•
    if text_cols is None:
        # ×‘×¨×™×¨×ª ××—×“×œ: ×›×œ ×”×¢××•×“×•×ª ×˜×§×¡×˜×•××œ×™×•×ª (××ª×” ×™×›×•×œ ×œ×©× ×•×ª)
        text_cols = df.select_dtypes(include=["object", "string"]).columns.tolist()
        if not text_cols:
            # ×× ××™×Ÿ ×¢××•×“×•×ª ×˜×§×¡×˜ â€” ×”××™×¨ ×©×•×¨×•×ª ×œ×™×™×¦×•×’
            text_cols = df.columns.tolist()

    docs = df_to_documents(df, text_cols)
    texts = [d.page_content for d in docs]

    embedder = Embedder(cfg)

    if recreate or not os.path.exists(index_path + ".pkl"):
        # ×¦×•×¨ embeddings
        vectors = embedder.embed_texts(texts)
        # build FAISS
        store = FAISS.from_documents(docs, embedder.emb if embedder.use_openai else None) if embedder.use_openai else None
        # ×× ××™×Ÿ ×ª××™×›×” ×™×©×™×¨×” ×‘Ö¾from_documents ×¢× sentence-transformers, × ×‘× ×” ×™×“× ×™:
        if store is None:
            import faiss
            dim = len(vectors[0])
            xb = np.array(vectors).astype("float32")
            index = faiss.IndexFlatL2(dim)
            index.add(xb)
            store = FAISS(embedding_function=None, index=index, docs=docs)  # embedding_function None ×œ×©×™××•×© ×¤× ×™××™
            # ×©×™× ×œ×‘: ×”×“×¨×š ×”×–×• ×©×•××¨×ª ××™× ×“×§×¡ ××š ×œ× ×‘×•× ×” ×—×™×‘×•×¨ ×—×›× ×›××• ×¡×¤×¨×™×•×ª ×—×“×©×•×ª ×™×•×ª×¨.
        store.save_local(index_path)
    else:
        store = FAISS.load_local(index_path, embedder.emb if embedder.use_openai else None)

    return store

def create_qa_chain(vectorstore, cfg_path="config.json"):
    cfg = load_config(cfg_path)
    if cfg["openai"].get("use_openai", True):
        model_name = cfg["openai"].get("model", "gpt-4o-mini")
        llm = ChatOpenAI(model=model_name, temperature=0)
    else:
        raise ValueError("Local LLM not implemented in this example. Set use_openai=true in config.")
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 4})
    qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever, return_source_documents=True)
    return qa

def ask_question(qa_chain, question: str):
    res = qa_chain({"query": question})
    answer = res["result"]
    sources = res.get("source_documents", [])
    return answer, sources
